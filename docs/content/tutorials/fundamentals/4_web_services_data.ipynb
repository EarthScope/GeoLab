{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe38ad28-c3c2-48be-946b-5352eae82ded",
   "metadata": {},
   "source": [
    "# Getting Data from Web Services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1c2659-11c1-4f59-9903-9681a4bb8434",
   "metadata": {},
   "source": [
    "This section details how to get seismic data from EarthScope web services. This section requires a working knowledge of Python. You should have an understanding of data types and string formatting, creating file paths and file naming, web requests, and creating Python functions. In addition to Python, you should have an understanding of miniSEED data distributed through the International Federation of Digital Seismograph Networks (FDSN). \n",
    "\n",
    "The notebook material is informational and is useful for completing the [**web service exercise**](./5_web_services_exercise.ipynb).\n",
    "\n",
    "![](images/Web_Services_Data_Flow.png)\n",
    "\n",
    "## Getting Seismic Data from SAGE Web Services\n",
    "\n",
    "The `fdsnws-dataselect` service provides access to time series data for specified channels and time ranges. Dataselect implements the [FDSN web service specification](https://www.fdsn.org/webservices/).\n",
    "\n",
    "Data queries use SEED time series identifiers (network, station, location & channel) in addition to time ranges. Returned data formats include miniSEED, SAC zip, and GeoCSV.\n",
    "\n",
    "To create a request, the Dataselect API takes these parameters at a minimum:\n",
    "\n",
    "| parameters | examples | discussion | default |type |\n",
    "| ---------- | -------- | ---------- | ------- |-----|\n",
    "| start[time] |\t2010-02-27T06:30:00\t| Specifies the desired start-time for miniSEED data | | day/time |\n",
    "| end[time]\t| 2010-02-27T10:30:00 | Specify the end-time for the miniSEED data | | day/time | \n",
    "|net[work] | IU | Select one or more network codes. Accepts wildcards and lists. Can be SEED codes or data center-defined codes. | any | string |\n",
    "| sta[tion] | ANMO | Select one or more SEED station codes. Accepts wildcards and lists. | any| string |\n",
    "|loc[ation] |00 | Select one or more SEED location identifiers. Accepts wildcards and lists. Use -- for “Blank” location IDs (ID’s containing 2 spaces). | any | string |\n",
    "| cha[nnel] | BHZ | Select one or more SEED channel codes. Accepts wildcards and lists. | any | string |\n",
    "\n",
    "To download a file, we can use the `requests` package to send the HTTP request to the dataselect web service. As discussed in the previous section, the request must include an authorization token using the `get_token` function.\n",
    "\n",
    "The `download_data` function requires the query parameters required by the FDSN Web Service specification, and where to write the data. The function does several things. First, it requests an authorization token. Next, it creates a file name for the data. Finally, it sends the request to dataselect and writes the data to a file in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e1f63-bc44-49fd-8876-1e501731ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from earthscope_sdk import EarthScopeClient\n",
    "\n",
    "# SAGE archive\n",
    "URL = \"http://service.iris.edu/fdsnws/dataselect/1/query?\"\n",
    "\n",
    "# function to get authorization token \n",
    "def get_token():\n",
    "    \n",
    "    # refresh the token if it has expired\n",
    "    client.ctx.auth_flow.refresh_if_necessary()\n",
    "\n",
    "    token = client.ctx.auth_flow.access_token\n",
    "    \n",
    "    return token\n",
    "\n",
    "def download_data(params, data_directory):\n",
    "\n",
    "    # get authorization Bearer token\n",
    "    token = get_token()\n",
    "\n",
    "    # get year and day from string start time\n",
    "    start_date = datetime.strptime(params['start'], '%Y-%m-%dT%H:%M:%S')\n",
    "    year = start_date.year\n",
    "    day = start_date.day\n",
    "    \n",
    "    \n",
    "    # file name format: STATION.NETWORK.YEAR.DAYOFYEAR\n",
    "    file_name = \".\".join([params[\"sta\"], params[\"net\"],params['loc'],params['cha'], str(year), \"{:03d}\".format(day),'mseed'])\n",
    "    \n",
    "    \n",
    "    r = requests.get(URL, params=params, headers={\"authorization\": f\"Bearer {token}\"}, stream=True)\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        # save the file\n",
    "        with open(Path(Path(data_directory) / file_name), 'wb') as f:\n",
    "            for data in r:\n",
    "                f.write(data)\n",
    "    else:\n",
    "        #problem occured\n",
    "        print(f\"failure: {r.status_code}, {r.reason}\")\n",
    "        \n",
    "\n",
    "# create client to get token\n",
    "client = EarthScopeClient()\n",
    "\n",
    "# create directory for data\n",
    "data_directory = \"./miniseed_data\"\n",
    "os.makedirs(data_directory, exist_ok=True)\n",
    "\n",
    "# parameters specifying the miniSEED file\n",
    "params = {\"net\" : 'IU',\n",
    "          \"sta\" : 'ANMO',\n",
    "          \"loc\" : '00',\n",
    "          \"cha\" : 'BHZ',\n",
    "          \"start\": '2010-02-27T06:30:00',\n",
    "          \"end\": '2010-02-27T10:30:00'}\n",
    "\n",
    "download_data(params, data_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af147c9-1b77-48b4-bd07-e785afaab7fb",
   "metadata": {},
   "source": [
    "## Getting Geodetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5c7b42-29c2-41d4-9853-6a3f44e2b278",
   "metadata": {},
   "source": [
    "This section details how to get geodetic data from EarthScope services. This section requires a working knowledge of Python. You should have an understanding of data types and string formatting, creating file paths and file naming, web requests, and creating Python functions. In addition to Python, you should have an understanding of GNSS data types and formats. \n",
    "\n",
    "The notebook material is informational and is useful for completing the [**web service exercise**](./5_web_services_exercise.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd6b6f-1834-4831-b620-b17d4b1e41fe",
   "metadata": {},
   "source": [
    "## Getting Geodetic Data from GAGE Web Services\n",
    "\n",
    "The GAGE archive holds many types of data ranging from GPS/GNSS data to borehole strain data. We will focus on GPS/GNSS data. Each type of data has API interfaces specific to the data. Unlike dataselect, the API calls return information about data or processed data. The collected data is distributed by a file server and can be programatically downloaded if you know the URL to the file.\n",
    "\n",
    "In this example, we will download GNSS data in RINEX. GAGE data is located on a file server and data cab be downloaded with a properly formatted URL. The script downloads the stations by providing the parameters that make up the URL to the data. \n",
    "\n",
    "### Downloading RINEX files\n",
    "\n",
    "The GAGE base URL for gnss data in RINEX is `https://gage-data.earthscope.org/archive/gnss/rinex/obs/`. \n",
    "\n",
    "Files are organized by year and the day of the year, e.g., `/2025/001/`. File names use this pattern: \n",
    "\n",
    "| station | day of year | 0. | two digit year | o.Z or d.Z |\n",
    "|---------|-------------|----|----------------|-----|\n",
    "| p034 | 001 |0. | 25 | d.Z |\n",
    "| p034 | 001 |0. | 25 | o.Z |\n",
    "\n",
    "The complete URL for this RINEX file:\n",
    "\n",
    "`https://gage-data.earthscope.org/archive/gnss/rinex/obs/2025/001/p0340010.25d.Z`\n",
    "\n",
    "> Note: files ending with `d.Z` are [hatanaka compressed files](https://www.unavco.org/data/gps-gnss/hatanaka/hatanaka.html) and files ending with `o.Z` are not hatanaka compressed. Hatanaka compressed files are much smaller but require software to read the data.\n",
    "\n",
    "The same method for downloading SAGE data can be used to download GAGE data once URL is properly constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9943e48d-7801-4846-9f63-9399c6b0ddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "from pathlib import Path\n",
    "from earthscope_sdk import EarthScopeClient\n",
    "\n",
    "client = EarthScopeClient()\n",
    "\n",
    "BASE_URL= 'https://gage-data.earthscope.org/archive/gnss/rinex/obs/'\n",
    "\n",
    "# function to get authorization token \n",
    "def get_token():\n",
    "    \n",
    "    # refresh the token if it has expired\n",
    "    client.ctx.auth_flow.refresh_if_necessary()\n",
    "\n",
    "    token = client.ctx.auth_flow.access_token\n",
    "    \n",
    "    return token\n",
    "\n",
    "# function to download data from GAGE archive\n",
    "def download_file(url, data_directory):\n",
    "    \n",
    "    # get authorization Bearer token\n",
    "    token = get_token()\n",
    "\n",
    "    # the pathlib package (https://docs.python.org/3/library/pathlib.html#accessing-individual-parts) \n",
    "    # supports extracting the file name from the end of a path\n",
    "    file_name = Path(url).name\n",
    "    \n",
    "    # request a file and provide the token in the Authorization header\n",
    "    r = requests.get(url, headers={\"authorization\": f\"Bearer {token}\"}, stream=True)\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        # save the file\n",
    "        with open(Path(Path(data_directory) / file_name), 'wb') as f:\n",
    "            for data in r:\n",
    "                f.write(data)\n",
    "    else:\n",
    "        #problem occured\n",
    "        print(f\"failure: {r.status_code}, {r.reason}\")\n",
    "\n",
    "# function to creat URL to download data\n",
    "def create_url(year, day, station, compression):\n",
    "    # using Python string formatting and slicing\n",
    "    doy = \"{:03d}\".format(day) # converts day to a three character zero padded string , '001'\n",
    "    two_digit_year = str(year)[2:] # converts integer to string and slices the last characters\n",
    "\n",
    "    # using the Python join method to concatenate an array or list of strings\n",
    "    file_path = '/'.join([str(year), doy]) # integer year converted to string for string join\n",
    "    file_name = ''.join(['/', station, doy, '0.', two_digit_year, compression])\n",
    "    url = ''.join([BASE_URL,file_path,file_name])\n",
    "\n",
    "    return url\n",
    "\n",
    "# create a directory for rinex data\n",
    "directory_path = \"./rinex_data\"\n",
    "os.makedirs(directory_path, exist_ok=True)\n",
    "\n",
    "# data requested from station p034 on January 1, 2025 hatanaka compressed\n",
    "year = 2025\n",
    "day = 1\n",
    "station = 'p034'\n",
    "compression = 'd.Z'\n",
    "\n",
    "# download the RINEX file\n",
    "url = create_url(year, day, station, compression)\n",
    "download_file(url, directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e801b2-4564-493d-ab7f-6343872640f9",
   "metadata": {},
   "source": [
    "In this example, we’ve added a function to create a URL to the data. The URL can be constructed more succinctly. However, the example demonstrates how to format parameters using Python string functions and how to join strings to form a URL.\n",
    "A more succinct method for building the URL would be to use string formatting and add the following code to the download_file function, along with the required parameters. However, this is less explicit and illustrative.\n",
    "\n",
    "```python\n",
    "doy = '{%03d}'.format(day)\n",
    "two_digit_year = str(year)[2:]\n",
    "url='https://gage-data.earthscope.org/archive/gnss/rinex/obs/{}/{}/{}{}.{}d.Z'.format(year,doy,station,doy,two_digit_year)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c43c58-49e0-43f2-b9bd-49b2456c5983",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Web services are a convenient way to download data files in known formats. However, downloading incurs a penalty because the file is written locally and must be read for processing and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c41243-75e2-41a0-99a8-339c4ad0613a",
   "metadata": {},
   "source": [
    "## [< Previous](./3_authorization.ipynb)&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;[Next >](./5_web_services_exercise.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
